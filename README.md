ğŸ Task 5: Python Basics â€“ Reading Data & Simple Cleaning (Pandas)
ğŸ“Œ Project Overview

This task focuses on using Python with Pandas to perform basic data cleaning operations that are commonly done manually in Excel.
The objective is to learn how Python can automate data cleaning for large datasets efficiently.

ğŸ“‚ Dataset

One of the following datasets was used:

Titanic Dataset

House Prices Dataset

Students Performance Dataset

ğŸ›  Tools & Libraries

Primary: Google Colab

Alternatives: Jupyter Notebook, Kaggle Notebooks

Libraries:

pandas

numpy

ğŸ“ Project Files
File	Description
Task5_Cleaning.ipynb	Jupyter notebook with all cleaning steps
cleaned_data.csv	Final cleaned dataset
README.md	Project documentation
ğŸ”¹ Step 1: Import Libraries & Load Data
import pandas as pd
import numpy as np

df = pd.read_csv("titanic.csv")
df.head()


ğŸ“Œ Purpose: Load dataset and preview first few rows.

ğŸ”¹ Step 2: Understand Data Structure
df.info()
df.shape


ğŸ“Œ Purpose: Check columns, data types, and total records.

ğŸ”¹ Step 3: Identify Missing Values
df.isnull().sum()


ğŸ“Œ Purpose: Find which columns have missing data.

ğŸ”¹ Step 4: Handle Missing Values
# Fill numeric columns with mean
df['Age'] = df['Age'].fillna(df['Age'].mean())

# Fill categorical columns with mode
df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])


ğŸ“Œ Purpose: Prepare data for analysis or modeling.

ğŸ”¹ Step 5: Remove Duplicates
before = df.shape[0]
df = df.drop_duplicates()
after = df.shape[0]

print("Rows before:", before)
print("Rows after:", after)


ğŸ“Œ Purpose: Ensure no duplicate records exist.

ğŸ”¹ Step 6: Convert Data Types
df['Survived'] = df['Survived'].astype(int)


ğŸ“Œ Purpose: Make sure data types are correct for calculations.

ğŸ”¹ Step 7: Create New Column

Example: Age Category

df['Age_Group'] = np.where(df['Age'] < 18, 'Child', 'Adult')


ğŸ“Œ Purpose: Feature engineering / transformation.

ğŸ”¹ Step 8: Save Cleaned Dataset
df.to_csv("cleaned_data.csv", index=False)
